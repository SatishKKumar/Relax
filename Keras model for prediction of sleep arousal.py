"""Neural Networks
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1mXBH6KcZM7Hr3no6iMJjdY-ao0uryHz3
"""

from sklearn.metrics import confusion_matrix, precision_score
from sklearn.model_selection import train_test_split
from keras.layers import Dense, Dropout, Flatten
from keras.models import Sequential
from keras.regularizers import l2
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from keras.layers import Conv1D
from keras.layers.convolutional import Convolution1D
from keras.utils import to_categorical

from google.colab import drive
drive.mount('/content/drive')

data=pd.read_csv('/content/drive/My Drive/finaldata.csv')

data.drop(['Unnamed: 0'],axis=1,inplace=True)

data.head()

data.shape

X=data.drop(columns=['143'])

Y=data['143']

## Train - Test Split

x_train.shape

x_train=np.array(x_train).reshape(x_train.shape[0],x_train.shape[1],1)

x_train.shape

x_test=np.array(x_test).reshape(x_test.shape[0],x_test.shape[1],1)

x_train=np.array(x_train).reshape(256,143,1)

x_train.shape

y_train_one.shape

data_train = y_train
data_test = y_test
# one hot encode
y_test_one = to_categorical(data_test)
#print(y_test_one)
y_train_one = to_categorical(data_train)
#print(y_test_one)

num_classes=len(np.unique(y_train))
num_classes

model = Sequential()
model.add(Conv1D(128, kernel_size=3, input_shape=(143,1), activation='relu'))
#model.add(Flatten())
model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(x_train.shape[1:])))
model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
model.add(Conv1D(64, 10, activation='relu'))
model.add(Flatten())
model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01)))
#model.add(Dropout(0.1,noise_shape=None,seed=None))
model.add(Dense(50, activation='sigmoid', kernel_regularizer=l2(0.01)))
#model.add(Dropout(0.2,noise_shape=None,seed=None))
model.add(Dense(10, activation='relu', kernel_regularizer=l2(0.01)))
#model.add(Dropout(0.1,noise_shape=None,seed=None))


model.add(Dense(2,activation='relu'))

model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])

model.summary()

history=model.fit(x_train,y_train_one,epochs=50,)

model.evaluate(x_test, y_test_one, batch_size=32)

model.save("model.h5")




